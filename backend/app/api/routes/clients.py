from fastapi import APIRouter, Depends, HTTPException, status, Query, UploadFile, File
from sqlalchemy.orm import Session
from typing import List, Optional
import csv
import io
import re
import logging
from app.db.session import get_db
from app.db.models.client import Client
from app.api.schemas.client import ClientCreate, ClientUpdate, ClientRead, ClientWithStats
from app.api.deps import get_current_active_user
from app.db.models.user import User

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/clients", tags=["clients"])


def clean_control_characters(text: str) -> str:
    """
    Nettoie une cha√Æne en supprimant les caract√®res probl√©matiques pour PostgreSQL.
    Supprime les caract√®res de contr√¥le, les caract√®res invalides, et normalise l'encodage.
    """
    if not text:
        return text
    
    try:
        # D'abord, essayer de d√©coder/re-encoder pour √©liminer les caract√®res invalides
        # Cela g√®re les probl√®mes d'encodage comme '√∞' qui est un caract√®re mal encod√©
        text = text.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')
    except:
        pass
    
    # Supprimer les caract√®res de contr√¥le probl√©matiques (0x00-0x1F sauf \n, \r, \t)
    # Garder seulement les caract√®res imprimables et les retours √† la ligne normaux
    cleaned = ''.join(
        char for char in text 
        if (ord(char) >= 32 and ord(char) < 0xD800) or char in '\n\r\t'
        # Exclure les caract√®res de substitution (0xFFFD) et autres caract√®res probl√©matiques
        and ord(char) != 0xFFFD
    )
    
    # Nettoyer les espaces multiples (mais PAS les retours √† la ligne, n√©cessaires pour le CSV)
    # Remplacer seulement les espaces/tabs multiples par un seul espace, en pr√©servant les \n et \r
    cleaned = re.sub(r'[ \t]+', ' ', cleaned)  # Remplacer espaces/tabs multiples par un seul espace
    # Nettoyer les retours √† la ligne multiples (mais garder au moins un \n)
    cleaned = re.sub(r'\n\s*\n+', '\n', cleaned)  # Remplacer lignes vides multiples par une seule ligne vide
    cleaned = cleaned.strip()
    
    return cleaned


def sanitize_csv_text(text: str) -> str:
    """
    Nettoie le texte CSV en corrigeant les probl√®mes de format, notamment les retours √† la ligne
    dans les champs non quot√©s. Cette fonction est une solution de contournement pour les CSV malform√©s.
    """
    if not text:
        return text
    
    lines = text.split('\n')
    if len(lines) < 2:
        return text
    
    # Lire l'en-t√™te et nettoyer les caract√®res de contr√¥le
    header = clean_control_characters(lines[0])
    sanitized_lines = [header]
    
    # Compter le nombre de colonnes attendues
    try:
        header_reader = csv.reader([header])
        expected_cols = len(next(header_reader))
    except:
        # Fallback : compter les virgules (approximation)
        expected_cols = header.count(',') + 1
    
    # Traiter les lignes de donn√©es
    i = 1
    while i < len(lines):
        line = clean_control_characters(lines[i].rstrip('\r'))
        
        if not line.strip():
            i += 1
            continue
        
        # Essayer de parser la ligne pour voir si elle est valide
        is_valid = False
        try:
            test_reader = csv.reader([line])
            row = next(test_reader)
            if len(row) == expected_cols:
                is_valid = True
        except (csv.Error, StopIteration):
            pass
        
        if is_valid:
            # La ligne est valide
            sanitized_lines.append(line)
            i += 1
        else:
            # La ligne n'est pas valide, probablement √† cause d'un retour √† la ligne dans un champ
            # Concat√©ner avec les lignes suivantes jusqu'√† avoir une ligne valide
            combined = line
            j = i + 1
            max_attempts = 20  # Limiter les tentatives
            attempts = 0
            
            while j < len(lines) and attempts < max_attempts:
                next_line = lines[j].rstrip('\r')
                if not next_line.strip():
                    j += 1
                    continue
                
                # Ajouter un espace au lieu d'un retour √† la ligne
                combined += " " + next_line
                
                # Tester si la ligne combin√©e est maintenant valide
                try:
                    test_reader = csv.reader([combined])
                    row = next(test_reader)
                    if len(row) == expected_cols:
                        is_valid = True
                        break
                except (csv.Error, StopIteration):
                    pass
                
                j += 1
                attempts += 1
            
            if is_valid:
                sanitized_lines.append(combined)
            else:
                # Si on n'a pas r√©ussi √† cr√©er une ligne valide, utiliser la ligne originale
                # et remplacer les retours √† la ligne par des espaces
                sanitized_lines.append(combined.replace('\n', ' ').replace('\r', ' '))
            
            i = j
    
    return '\n'.join(sanitized_lines)


@router.get("", response_model=List[ClientRead])
def get_clients(
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=10000),  # Augment√© √† 10000 pour permettre l'export complet
    search: Optional[str] = Query(None, description="Recherche par nom, email, t√©l√©phone"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    R√©cup√®re la liste des clients de l'entreprise de l'utilisateur.
    Chaque entreprise voit uniquement ses propres clients.
    """
    if current_user.company_id is None:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="User is not attached to a company"
        )
    
    # Base query : filtrer par company_id
    query = db.query(Client).filter(Client.company_id == current_user.company_id)
    
    # Recherche optionnelle
    if search:
        search_term = f"%{search.lower()}%"
        query = query.filter(
            (Client.name.ilike(search_term)) |
            (Client.email.ilike(search_term)) |
            (Client.phone.ilike(search_term))
        )
    
    # Pagination
    clients = query.order_by(Client.name.asc()).offset(skip).limit(limit).all()
    
    return clients


@router.get("/{client_id}", response_model=ClientRead)
def get_client(
    client_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    R√©cup√®re un client sp√©cifique par son ID.
    V√©rifie que le client appartient √† l'entreprise de l'utilisateur.
    """
    if current_user.company_id is None:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="User is not attached to a company"
        )
    
    client = db.query(Client).filter(
        Client.id == client_id,
        Client.company_id == current_user.company_id
    ).first()
    
    if not client:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Client not found"
        )
    
    return client


@router.post("", response_model=ClientRead, status_code=status.HTTP_201_CREATED)
def create_client(
    client_data: ClientCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Cr√©e un nouveau client pour l'entreprise de l'utilisateur.
    """
    if current_user.company_id is None:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="User is not attached to a company"
        )
    
    # V√©rifier les limites d'utilisation selon le plan
    from app.core.subscription_limits import check_clients_limit
    is_allowed, error_message = check_clients_limit(db, current_user.company_id)
    if not is_allowed:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail=error_message
        )
    
    # Cr√©er le client
    client = Client(
        company_id=current_user.company_id,
        name=client_data.name,
        email=client_data.email,
        phone=client_data.phone,
        sector=client_data.sector,
        address=client_data.address,
        city=client_data.city,
        postal_code=client_data.postal_code,
        country=client_data.country,
        siret=client_data.siret,
        notes=client_data.notes,
        type=client_data.type or "Client",
        tags=client_data.tags or [],
    )
    
    db.add(client)
    db.commit()
    db.refresh(client)
    
    return client


@router.patch("/{client_id}", response_model=ClientRead)
def update_client(
    client_id: int,
    client_data: ClientUpdate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Met √† jour un client existant.
    V√©rifie que le client appartient √† l'entreprise de l'utilisateur.
    """
    if current_user.company_id is None:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="User is not attached to a company"
        )
    
    client = db.query(Client).filter(
        Client.id == client_id,
        Client.company_id == current_user.company_id
    ).first()
    
    if not client:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Client not found"
        )
    
    # Mettre √† jour uniquement les champs fournis
    update_data = client_data.model_dump(exclude_unset=True)
    for field, value in update_data.items():
        setattr(client, field, value)
    
    db.commit()
    db.refresh(client)
    
    return client


@router.delete("/{client_id}", status_code=status.HTTP_204_NO_CONTENT)
def delete_client(
    client_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Supprime un client.
    V√©rifie que le client appartient √† l'entreprise de l'utilisateur.
    """
    if current_user.company_id is None:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="User is not attached to a company"
        )
    
    client = db.query(Client).filter(
        Client.id == client_id,
        Client.company_id == current_user.company_id
    ).first()
    
    if not client:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Client not found"
        )
    
    db.delete(client)
    db.commit()
    
    return


@router.post("/import", response_model=dict)
async def import_clients_csv(
    file: UploadFile = File(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Importe des clients depuis un fichier CSV.
    Format attendu : Nom, Email, T√©l√©phone, Adresse, Ville, Code postal, Pays, SIRET
    """
    if current_user.company_id is None:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="User is not attached to a company"
        )
    
    # V√©rifier que c'est un fichier CSV
    if not file.filename or not file.filename.endswith('.csv'):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=(
                "‚ùå Format de fichier incorrect\n\n"
                "Le fichier doit avoir l'extension .csv\n\n"
                "üîç Causes probables :\n"
                "‚Ä¢ Vous avez s√©lectionn√© un fichier Excel (.xlsx, .xls)\n"
                "‚Ä¢ Vous avez s√©lectionn√© un fichier Numbers\n"
                "‚Ä¢ Le fichier n'a pas d'extension\n\n"
                "‚úÖ Solutions :\n"
                "1. Exportez votre fichier depuis Excel/Numbers en format CSV\n"
                "2. Le fichier doit se terminer par .csv\n"
                "3. Utilisez la fonction d'export de Lokario pour obtenir un fichier CSV valide"
            )
        )
    
    company_id = current_user.company_id
    created_count = 0
    updated_count = 0
    error_count = 0
    errors = []
    
    try:
        # Lire le contenu du fichier
        content = await file.read()
        
        # D√©tecter si c'est un fichier Excel/Numbers (format binaire) plut√¥t qu'un CSV texte
        # Les fichiers Excel/Numbers commencent souvent par des signatures binaires sp√©cifiques
        excel_signatures = [
            b'PK\x03\x04',  # ZIP/Excel (.xlsx)
            b'\xd0\xcf\x11\xe0',  # OLE2/Excel (.xls)
            b'PK\x05\x06',  # ZIP (Numbers peut utiliser ZIP)
        ]
        
        is_binary = any(content.startswith(sig) for sig in excel_signatures)
        
        # V√©rifier aussi si le fichier contient beaucoup de caract√®res non-textuels
        if not is_binary:
            # Compter les caract√®res non-textuels (hors ASCII imprimable, \n, \r, \t)
            non_text_count = sum(1 for b in content[:1000] if b < 32 and b not in [9, 10, 13])
            if non_text_count > 50:  # Si plus de 5% de caract√®res non-textuels dans les 1000 premiers bytes
                is_binary = True
        
        if is_binary:
            logger.error(f"[CSV Import] Fichier d√©tect√© comme binaire (Excel/Numbers), pas un CSV texte")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=(
                    "‚ùå Format de fichier incorrect\n\n"
                    "Le fichier que vous avez envoy√© semble √™tre un fichier Excel (.xlsx, .xls) ou Numbers, "
                    "et non un fichier CSV texte.\n\n"
                    "üîç Causes probables :\n"
                    "‚Ä¢ Vous avez renomm√© un fichier Excel en .csv sans l'exporter\n"
                    "‚Ä¢ Le fichier a √©t√© sauvegard√© dans un format binaire\n"
                    "‚Ä¢ Le fichier provient d'une application qui g√©n√®re des fichiers Excel\n\n"
                    "‚úÖ Solution :\n"
                    "1. Ouvrez votre fichier dans Excel ou Numbers\n"
                    "2. Allez dans Fichier > Exporter > CSV (ou Format CSV)\n"
                    "3. Choisissez l'encodage UTF-8 si propos√©\n"
                    "4. R√©essayez l'import avec le fichier export√©\n\n"
                    "üí° Astuce : Utilisez la fonction d'export de Lokario pour obtenir un fichier CSV valide."
                )
            )
        
        logger.info(f"[CSV Import] D√©but import: {file.filename} ({len(content) / (1024*1024):.2f} MB)")
        logger.info(f"[CSV Import] Premiers 200 bytes (hex): {content[:200].hex()}")
        logger.info(f"[CSV Import] Premiers 200 bytes (repr): {repr(content[:200])}")
        
        # D√©coder en UTF-8 (g√©rer BOM si pr√©sent)
        try:
            text = content.decode('utf-8-sig')  # utf-8-sig g√®re le BOM
            logger.info(f"[CSV Import] D√©codage UTF-8-sig r√©ussi")
        except UnicodeDecodeError:
            try:
                text = content.decode('latin-1')
                logger.info(f"[CSV Import] D√©codage Latin-1 r√©ussi")
            except UnicodeDecodeError:
                logger.error(f"[CSV Import] Impossible de d√©coder le fichier (ni UTF-8, ni Latin-1)")
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=(
                        "‚ùå Erreur d'encodage du fichier\n\n"
                        "Le fichier ne peut pas √™tre lu car son encodage n'est pas reconnu.\n\n"
                        "üîç Causes probables :\n"
                        "‚Ä¢ Le fichier utilise un encodage non standard (ex: Windows-1252, ISO-8859-15)\n"
                        "‚Ä¢ Le fichier contient des caract√®res sp√©ciaux mal encod√©s\n"
                        "‚Ä¢ Le fichier a √©t√© cr√©√© avec un √©diteur qui utilise un encodage diff√©rent\n\n"
                        "‚úÖ Solutions :\n"
                        "1. R√©exportez votre fichier depuis Excel/Numbers en choisissant UTF-8\n"
                        "2. Ouvrez le fichier dans un √©diteur de texte (TextEdit, Notepad++)\n"
                        "3. Sauvegardez-le en UTF-8 (Fichier > Enregistrer sous > Encodage: UTF-8)\n"
                        "4. R√©essayez l'import\n\n"
                        "üí° Astuce : Utilisez la fonction d'export de Lokario pour obtenir un fichier avec le bon encodage."
                    )
                )
        
        # Log les premiers caract√®res du texte d√©cod√©
        logger.info(f"[CSV Import] Premiers 500 caract√®res du texte d√©cod√©: {repr(text[:500])}")
        
        # Normaliser les retours √† la ligne (unifier en \n)
        text_normalized = text.replace('\r\n', '\n').replace('\r', '\n')
        
        # Supprimer les caract√®res de contr√¥le probl√©matiques (NUL, etc.)
        text_normalized = clean_control_characters(text_normalized)
        
        logger.info(f"[CSV Import] Texte normalis√© - longueur: {len(text_normalized)} caract√®res")
        logger.info(f"[CSV Import] Premiers 500 caract√®res apr√®s normalisation: {repr(text_normalized[:500])}")
        
        # Nettoyer le CSV pour corriger les probl√®mes de format (retours √† la ligne dans les champs non quot√©s)
        try:
            text_sanitized = sanitize_csv_text(text_normalized)
        except Exception as e:
            # Si le nettoyage √©choue, utiliser le texte original
            text_sanitized = text_normalized
        
        # Parser le CSV avec une configuration robuste
        csv_file = io.StringIO(text_sanitized)
        
        try:
            csv_reader = csv.DictReader(
                csv_file,
                quoting=csv.QUOTE_MINIMAL,
                doublequote=True,
                skipinitialspace=True
            )
        except csv.Error as e:
            # Si erreur de parsing CSV, fournir un message plus clair
            error_msg = str(e)
            if "new-line character seen in unquoted field" in error_msg.lower():
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=(
                        "‚ùå Format CSV invalide : retours √† la ligne dans les champs\n\n"
                        "Le fichier CSV contient des retours √† la ligne dans des champs qui ne sont pas entre guillemets.\n\n"
                        "üîç Causes probables :\n"
                        "‚Ä¢ Un champ (adresse, notes, etc.) contient un retour √† la ligne\n"
                        "‚Ä¢ Le fichier a √©t√© modifi√© manuellement et les guillemets ont √©t√© supprim√©s\n"
                        "‚Ä¢ Le fichier a √©t√© export√© avec des param√®tres incorrects\n\n"
                        "‚úÖ Solutions :\n"
                        "1. Ouvrez votre fichier dans Excel/Numbers\n"
                        "2. V√©rifiez que les champs avec retours √† la ligne sont bien entre guillemets\n"
                        "3. R√©exportez en CSV en choisissant 'Tous les champs entre guillemets'\n"
                        "4. Ou utilisez la fonction d'export de Lokario pour obtenir un format valide\n\n"
                        "üí° Exemple correct :\n"
                        'Nom,Email,Adresse\n'
                        '"Dupont","dupont@example.com","123 Rue de la Paix\n'
                        'Appartement 4B"\n'
                    )
                )
            else:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=(
                        f"‚ùå Erreur de format CSV\n\n"
                        f"Le fichier ne peut pas √™tre lu correctement.\n\n"
                        f"üîç D√©tails techniques : {error_msg}\n\n"
                        f"‚úÖ Solutions :\n"
                        f"1. V√©rifiez que le fichier est bien un CSV texte (pas Excel)\n"
                        f"2. V√©rifiez que les colonnes sont s√©par√©es par des virgules\n"
                        f"3. V√©rifiez que les champs contenant des virgules sont entre guillemets\n"
                        f"4. R√©exportez depuis Excel/Numbers en format CSV\n"
                        f"5. Utilisez la fonction d'export de Lokario comme mod√®le"
                    )
                )
        
        # V√©rifier que les colonnes attendues sont pr√©sentes
        expected_columns = ["Nom", "Email", "T√©l√©phone", "Adresse", "Ville", "Code postal", "Pays", "SIRET"]
        reader_columns = csv_reader.fieldnames or []
        
        logger.info(f"[CSV Import] Colonnes trouv√©es dans le fichier: {reader_columns}")
        logger.info(f"[CSV Import] Nombre de colonnes: {len(reader_columns) if reader_columns else 0}")
        
        # V√©rifier si les colonnes semblent corrompues (contiennent beaucoup de caract√®res non-ASCII imprimables)
        if reader_columns:
            corrupted = False
            for col in reader_columns:
                if col:
                    # Compter les caract√®res non-ASCII imprimables
                    non_printable = sum(1 for c in col if ord(c) < 32 or ord(c) > 126)
                    if non_printable > len(col) * 0.3:  # Si plus de 30% de caract√®res non-ASCII imprimables
                        corrupted = True
                        logger.error(f"[CSV Import] Colonne corrompue d√©tect√©e: {repr(col[:100])}")
                        break
            
            if corrupted:
                logger.error(f"[CSV Import] Les colonnes semblent corrompues. Le fichier n'est probablement pas un CSV texte valide.")
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=(
                        "‚ùå Fichier CSV corrompu ou format invalide\n\n"
                        "Les colonnes du fichier contiennent des caract√®res invalides ou corrompus.\n\n"
                        "üîç Causes probables :\n"
                        "‚Ä¢ Le fichier a √©t√© renomm√© de .xlsx √† .csv sans √™tre export√©\n"
                        "‚Ä¢ Le fichier est un fichier Excel binaire, pas un CSV texte\n"
                        "‚Ä¢ Le fichier a √©t√© corrompu lors du transfert\n"
                        "‚Ä¢ Le fichier utilise un encodage incompatible\n\n"
                        "‚úÖ Solutions :\n"
                        "1. Ouvrez votre fichier dans Excel ou Numbers\n"
                        "2. Allez dans Fichier > Exporter > CSV (ou Format CSV)\n"
                        "3. Choisissez l'encodage UTF-8 si propos√©\n"
                        "4. Ne renommez PAS simplement le fichier, EXPORTEZ-le\n"
                        "5. R√©essayez l'import avec le fichier export√©\n\n"
                        "üí° Astuce : Utilisez la fonction d'export de Lokario pour obtenir un fichier CSV valide."
                    )
                )
        
        # Mapper les colonnes (g√©rer les variations de noms)
        column_mapping = {}
        for expected in expected_columns:
            # Chercher une correspondance exacte ou insensible √† la casse
            found = None
            for col in reader_columns:
                if col and col.strip().lower() == expected.lower():
                    found = col
                    break
            if found:
                column_mapping[expected] = found
        
        # Si aucune colonne n'a √©t√© trouv√©e, essayer avec les colonnes du fichier telles quelles
        if not column_mapping and reader_columns:
            # Utiliser les colonnes du fichier directement
            for i, col in enumerate(reader_columns):
                if i < len(expected_columns):
                    column_mapping[expected_columns[i]] = col
        
        logger.info(f"[CSV Import] Mapping des colonnes: {column_mapping}")
        
        if not column_mapping:
            logger.warning(f"[CSV Import] Aucune colonne n'a pu √™tre mapp√©e. Colonnes du fichier: {reader_columns}")
            found_cols = ', '.join(reader_columns[:10]) if reader_columns else 'Aucune'
            if len(reader_columns) > 10:
                found_cols += f" (et {len(reader_columns) - 10} autres)"
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=(
                    "‚ùå Colonnes manquantes ou incorrectes\n\n"
                    "Le fichier CSV ne contient pas les colonnes attendues.\n\n"
                    f"üìã Colonnes trouv√©es dans votre fichier : {found_cols}\n"
                    f"üìã Colonnes attendues : {', '.join(expected_columns)}\n\n"
                    "üîç Causes probables :\n"
                    "‚Ä¢ Les noms de colonnes sont diff√©rents (ex: 'nom' au lieu de 'Nom')\n"
                    "‚Ä¢ L'ordre des colonnes est diff√©rent (ce n'est pas un probl√®me normalement)\n"
                    "‚Ä¢ Le fichier n'a pas d'en-t√™te de colonnes\n"
                    "‚Ä¢ Le fichier utilise un s√©parateur diff√©rent (point-virgule au lieu de virgule)\n\n"
                    "‚úÖ Solutions :\n"
                    "1. V√©rifiez que la premi√®re ligne contient les noms de colonnes\n"
                    "2. Les colonnes sont insensibles √† la casse (Nom, nom, NOM fonctionnent)\n"
                    "3. Utilisez la fonction d'export de Lokario comme mod√®le\n"
                    "4. Si vous utilisez un s√©parateur diff√©rent, convertissez-le en virgules\n\n"
                    "üí° Astuce : Vous pouvez r√©organiser les colonnes dans n'importe quel ordre, "
                    "mais les noms doivent correspondre (insensible √† la casse)."
                )
            )
        
        # Traiter chaque ligne
        try:
            all_rows = list(csv_reader)  # Lire toutes les lignes d'un coup pour d√©tecter les erreurs de format t√¥t
            logger.info(f"[CSV Import] Nombre total de lignes lues: {len(all_rows)}")
            
            # Log la premi√®re ligne pour debug
            if all_rows:
                logger.info(f"[CSV Import] Premi√®re ligne de donn√©es: {dict(list(all_rows[0].items())[:5])}")
            
            # Filtrer les lignes compl√®tement vides (toutes les valeurs sont vides ou None)
            rows = []
            for row in all_rows:
                # V√©rifier si la ligne a au moins une valeur non vide
                has_data = any(
                    value and str(value).strip() 
                    for value in row.values() 
                    if value is not None
                )
                if has_data:
                    rows.append(row)
            
            logger.info(f"[CSV Import] Nombre de lignes avec donn√©es apr√®s filtrage: {len(rows)}")
            
            if len(rows) == 0:
                logger.warning(f"[CSV Import] Aucune ligne avec donn√©es trouv√©e apr√®s filtrage. Toutes les lignes sont vides.")
                # Log quelques lignes pour comprendre pourquoi elles sont filtr√©es
                for i, row in enumerate(all_rows[:5]):
                    logger.info(f"[CSV Import] Ligne {i+2} (exemple filtr√©): {dict(list(row.items())[:3])}")
                
                # Lever une exception explicative si aucune ligne n'est trouv√©e
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=(
                        "‚ùå Aucune donn√©e trouv√©e dans le fichier\n\n"
                        "Le fichier CSV ne contient aucune ligne de donn√©es valide.\n\n"
                        "üîç Causes probables :\n"
                        "‚Ä¢ Le fichier ne contient que l'en-t√™te (noms de colonnes) sans donn√©es\n"
                        "‚Ä¢ Toutes les lignes sont vides ou ne contiennent que des espaces\n"
                        "‚Ä¢ Le fichier a √©t√© mal export√© et les donn√©es n'ont pas √©t√© incluses\n"
                        "‚Ä¢ Le s√©parateur utilis√© n'est pas une virgule (ex: point-virgule, tabulation)\n\n"
                        "‚úÖ Solutions :\n"
                        "1. V√©rifiez que votre fichier contient au moins une ligne de donn√©es apr√®s l'en-t√™te\n"
                        "2. V√©rifiez que les donn√©es ne sont pas toutes vides\n"
                        "3. V√©rifiez que le s√©parateur est une virgule (pas un point-virgule)\n"
                        "4. R√©exportez depuis Excel/Numbers en format CSV\n"
                        "5. Utilisez la fonction d'export de Lokario comme mod√®le\n\n"
                        "üí° Format attendu :\n"
                        "Nom,Email,T√©l√©phone,Adresse,Ville,Code postal,Pays,SIRET\n"
                        "Dupont,dupont@example.com,0123456789,123 Rue de la Paix,Paris,75001,France,12345678901234"
                    )
                )
        except csv.Error as e:
            error_msg = str(e)
            if "new-line character seen in unquoted field" in error_msg.lower():
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=(
                        "‚ùå Format CSV invalide : retours √† la ligne dans les champs\n\n"
                        "Le fichier CSV contient des retours √† la ligne dans des champs qui ne sont pas entre guillemets.\n\n"
                        "üîç Causes probables :\n"
                        "‚Ä¢ Un champ (adresse, notes, etc.) contient un retour √† la ligne\n"
                        "‚Ä¢ Le fichier a √©t√© modifi√© manuellement et les guillemets ont √©t√© supprim√©s\n"
                        "‚Ä¢ Le fichier a √©t√© export√© avec des param√®tres incorrects\n\n"
                        "‚úÖ Solutions :\n"
                        "1. Ouvrez votre fichier dans Excel/Numbers\n"
                        "2. V√©rifiez que les champs avec retours √† la ligne sont bien entre guillemets\n"
                        "3. R√©exportez en CSV en choisissant 'Tous les champs entre guillemets'\n"
                        "4. Ou utilisez la fonction d'export de Lokario pour obtenir un format valide\n\n"
                        "üí° Exemple correct :\n"
                        'Nom,Email,Adresse\n'
                        '"Dupont","dupont@example.com","123 Rue de la Paix\n'
                        'Appartement 4B"'
                    )
                )
            else:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=(
                        f"‚ùå Erreur de format CSV lors de la lecture\n\n"
                        f"Le fichier ne peut pas √™tre lu correctement.\n\n"
                        f"üîç D√©tails techniques : {error_msg}\n\n"
                        f"‚úÖ Solutions :\n"
                        f"1. V√©rifiez que le fichier est bien un CSV texte (pas Excel)\n"
                        f"2. V√©rifiez que les colonnes sont s√©par√©es par des virgules\n"
                        f"3. V√©rifiez que les champs contenant des virgules sont entre guillemets\n"
                        f"4. R√©exportez depuis Excel/Numbers en format CSV\n"
                        f"5. Utilisez la fonction d'export de Lokario comme mod√®le"
                    )
                )
        
        # Faire un flush p√©riodique pour √©viter les probl√®mes de m√©moire avec les gros fichiers
        flush_interval = 100  # Flush tous les 100 clients
        
        for row_num, row in enumerate(rows, start=2):  # start=2 car ligne 1 = headers
            # Utiliser un try/except pour chaque ligne avec rollback en cas d'erreur
            try:
                # Extraire les donn√©es (g√©rer les colonnes avec ou sans mapping)
                # Les cases vides sont ignor√©es (retourne None)
                def get_value(key: str) -> Optional[str]:
                    mapped_key = column_mapping.get(key, key)
                    value = row.get(mapped_key, row.get(key, ""))
                    if value:
                        try:
                            # Nettoyer les caract√®res de contr√¥le probl√©matiques
                            value = clean_control_characters(str(value))
                            value = value.strip()
                            # Retourner None si la valeur est vide apr√®s nettoyage
                            return value if value else None
                        except Exception as e:
                            # Si le nettoyage √©choue, retourner None
                            return None
                    return None  # Case vide = None (ignor√©)
                
                name = get_value("Nom")
                email = get_value("Email")
                phone = get_value("T√©l√©phone")
                address = get_value("Adresse")
                city = get_value("Ville")
                postal_code = get_value("Code postal")
                country = get_value("Pays")
                siret = get_value("SIRET")
                
                # Log pour debug (premi√®res lignes seulement)
                if row_num <= 5:
                    logger.info(f"[CSV Import] Ligne {row_num} - Nom: '{name}', Email: '{email}', Phone: '{phone}'")
                    logger.info(f"[CSV Import] Ligne {row_num} - Row data (premiers champs): {dict(list(row.items())[:3])}")
                
                # V√©rifier si la ligne est compl√®tement vide (tous les champs sont vides)
                # Cela inclut les lignes avec seulement des espaces, des virgules, ou des caract√®res vides
                all_empty = not any([name, email, phone, address, city, postal_code, country, siret])
                if all_empty:
                    # Ignorer silencieusement les lignes compl√®tement vides
                    # Ces lignes sont probablement des lignes vides dans le CSV (espaces, virgules seules, etc.)
                    if row_num <= 5:
                        logger.info(f"[CSV Import] Ligne {row_num} ignor√©e (compl√®tement vide)")
                    continue
                
                # Au minimum, il faut un nom ou un email pour cr√©er/mettre √† jour un client
                if not name and not email:
                    error_count += 1
                    error_msg = f"Ligne {row_num}: Nom ou Email requis"
                    errors.append(error_msg)
                    if row_num <= 5:
                        logger.warning(f"[CSV Import] {error_msg}")
                    continue
                
                # Normaliser l'email (lowercase, trim) pour √©viter les doublons
                normalized_email = email.lower().strip() if email else None
                normalized_name = name.strip() if name else None
                
                # Chercher un client existant
                # R√®gle : Si on a un email, chercher uniquement par email (le plus fiable)
                # Si on n'a pas d'email mais un nom, chercher par nom
                existing_client = None
                if normalized_email:
                    # Priorit√© 1: Chercher par email (le plus fiable, √©vite les doublons)
                    existing_client = db.query(Client).filter(
                        Client.company_id == company_id,
                        Client.email.ilike(normalized_email)  # Case-insensitive
                    ).first()
                elif normalized_name:
                    # Priorit√© 2: Chercher par nom seulement si on n'a pas d'email
                    # (moins fiable car plusieurs clients peuvent avoir le m√™me nom)
                    existing_client = db.query(Client).filter(
                        Client.company_id == company_id,
                        Client.name.ilike(normalized_name),  # Case-insensitive
                        Client.email.is_(None)  # Seulement si le client n'a pas d'email
                    ).first()
                    
                    # Si pas trouv√© avec email=None, chercher par nom seul (m√™me avec email)
                    if not existing_client:
                        existing_client = db.query(Client).filter(
                            Client.company_id == company_id,
                            Client.name.ilike(normalized_name)  # Case-insensitive
                    ).first()
                
                if existing_client:
                    # Mettre √† jour le client existant (ne pas recr√©er)
                    # Mettre √† jour seulement les champs qui ont des valeurs (cases vides = ignor√©es)
                    if normalized_name:
                        existing_client.name = normalized_name
                    if normalized_email:
                        existing_client.email = normalized_email
                    if phone:  # Si case vide, phone est None, donc on ne met pas √† jour
                        existing_client.phone = phone
                    if address:  # Si case vide, address est None, donc on ne met pas √† jour
                        existing_client.address = address
                    if city:  # Si case vide, city est None, donc on ne met pas √† jour
                        existing_client.city = city
                    if postal_code:  # Si case vide, postal_code est None, donc on ne met pas √† jour
                        existing_client.postal_code = postal_code
                    if country:  # Si case vide, country est None, donc on ne met pas √† jour
                        existing_client.country = country
                    if siret:  # Si case vide, siret est None, donc on ne met pas √† jour
                        existing_client.siret = siret
                    # S'assurer que le type est d√©fini si ce n'est pas d√©j√† le cas
                    if not existing_client.type:
                        existing_client.type = "Client"
                    updated_count += 1
                else:
                    # Cr√©er un nouveau client seulement si on n'a pas trouv√© de client existant
                    if not normalized_name and not normalized_email:
                        # Ne devrait pas arriver car on a d√©j√† v√©rifi√© plus haut
                        error_count += 1
                        errors.append(f"Ligne {row_num}: Impossible de cr√©er un client sans nom ni email")
                        continue
                    
                    # Cr√©er un nouveau client
                    # Les cases vides (None) sont pass√©es directement, elles seront NULL en base de donn√©es
                    new_client = Client(
                        company_id=company_id,
                        name=normalized_name or "Client sans nom",
                        email=normalized_email,  # Peut √™tre None si case vide
                        phone=phone,  # Peut √™tre None si case vide (ignor√©)
                        address=address,  # Peut √™tre None si case vide (ignor√©)
                        city=city,  # Peut √™tre None si case vide (ignor√©)
                        postal_code=postal_code,  # Peut √™tre None si case vide (ignor√©)
                        country=country,  # Peut √™tre None si case vide (ignor√©)
                        siret=siret,  # Peut √™tre None si case vide (ignor√©)
                        type="Client",  # D√©finir le type par d√©faut
                    )
                    db.add(new_client)
                    created_count += 1
                
                # Flush et commit p√©riodique pour √©viter les probl√®mes de m√©moire et de transaction
                if (created_count + updated_count) % flush_interval == 0:
                    try:
                        db.flush()
                        db.commit()  # Commit p√©riodique pour √©viter les transactions trop longues
                    except Exception as flush_error:
                        # Si le flush/commit √©choue, rollback et continuer
                        db.rollback()
                        error_count += 1
                        errors.append(f"Ligne {row_num}: Erreur lors du flush/commit - {str(flush_error)}")
                        continue
                
            except Exception as e:
                # En cas d'erreur, rollback cette transaction et continuer avec la ligne suivante
                try:
                    db.rollback()
                except:
                    pass  # Ignorer les erreurs de rollback
                
                error_count += 1
                error_msg = str(e)
                # Raccourcir les messages d'erreur tr√®s longs
                if len(error_msg) > 200:
                    error_msg = error_msg[:200] + "..."
                errors.append(f"Ligne {row_num}: {error_msg}")
                continue
        
        # Commit toutes les modifications
        db.commit()
        
        logger.info(f"[CSV Import] Import termin√©. Cr√©√©s: {created_count}, Mis √† jour: {updated_count}, Erreurs: {error_count}")
        
        return {
            "message": "Import termin√©",
            "created": created_count,
            "updated": updated_count,
            "errors": error_count,
            "error_details": errors[:10] if errors else []  # Limiter √† 10 erreurs pour la r√©ponse
        }
    
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"[CSV Import] Erreur fatale lors de l'import: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur lors de l'import: {str(e)}"
        )

