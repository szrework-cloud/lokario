# ğŸ”§ Correction : Timeout du pool de connexions SQLAlchemy

## ğŸ”´ ProblÃ¨me

Vous avez rencontrÃ© cette erreur :
```
sqlalchemy.exc.TimeoutError: QueuePool limit of size 5 overflow 10 reached, 
connection timed out, timeout 30.00
```

## ğŸ” Cause

Le pool de connexions SQLAlchemy avait une configuration par dÃ©faut trop petite :
- **pool_size** : 5 connexions permanentes (par dÃ©faut)
- **max_overflow** : 10 connexions supplÃ©mentaires (par dÃ©faut)
- **Total maximum** : 15 connexions simultanÃ©es

Quand toutes les connexions sont occupÃ©es (15 requÃªtes simultanÃ©es), les nouvelles requÃªtes attendent 30 secondes puis Ã©chouent avec un timeout.

## âœ… Solution appliquÃ©e

J'ai configurÃ© le pool de connexions pour PostgreSQL/Supabase avec des paramÃ¨tres optimisÃ©s :

```python
engine = create_engine(
    settings.DATABASE_URL,
    pool_size=10,           # 10 connexions permanentes (au lieu de 5)
    max_overflow=20,        # 20 connexions supplÃ©mentaires (au lieu de 10)
    pool_timeout=30,        # 30 secondes d'attente
    pool_recycle=3600,      # Recycler les connexions aprÃ¨s 1h (important pour Supabase)
    pool_pre_ping=True,     # VÃ©rifier que les connexions sont vivantes avant utilisation
)
```

**Nouveau total** : **30 connexions maximum** (10 + 20) au lieu de 15.

## ğŸ“Š ParamÃ¨tres expliquÃ©s

### `pool_size=10`
- Nombre de connexions **permanentes** maintenues ouvertes
- AugmentÃ© de 5 Ã  10 pour supporter plus de requÃªtes simultanÃ©es

### `max_overflow=20`
- Nombre de connexions **supplÃ©mentaires** autorisÃ©es au-delÃ  de `pool_size`
- AugmentÃ© de 10 Ã  20
- Total maximum : 10 + 20 = **30 connexions simultanÃ©es**

### `pool_recycle=3600` (1 heure)
- **Crucial pour Supabase**
- Recycler les connexions aprÃ¨s 1 heure
- Supabase ferme les connexions inactives aprÃ¨s 1h, ce paramÃ¨tre Ã©vite d'utiliser des connexions mortes

### `pool_pre_ping=True`
- VÃ©rifier que la connexion est vivante avant de l'utiliser
- Si la connexion est morte, SQLAlchemy la recrÃ©e automatiquement
- **Important pour Supabase** qui peut fermer des connexions inactives

### `pool_timeout=30`
- Temps d'attente (en secondes) avant d'abandonner si toutes les connexions sont occupÃ©es
- 30 secondes est raisonnable (par dÃ©faut)

## âš ï¸ Limites Supabase

### Transaction Pooler (recommandÃ©)
- **Limite** : 100 connexions simultanÃ©es
- **UtilisÃ©** : Pooler sur le port **6543**
- âœ… Notre configuration (30 max) est bien en dessous de la limite

### Direct Connection
- **Limite** : Variable selon le plan Supabase
- **UtilisÃ©** : Port **5432**
- âš ï¸ Plus restrictif

**Assurez-vous d'utiliser le Transaction Pooler** (`:6543`) dans votre `DATABASE_URL` :
```
postgresql://postgres.xxx:password@aws-1-eu-west-3.pooler.supabase.com:6543/postgres
```

## ğŸ”„ Si le problÃ¨me persiste

### 1. VÃ©rifier les connexions actives dans Supabase

Dans le dashboard Supabase :
- Allez dans **Database** â†’ **Connection Pooling**
- VÃ©rifiez le nombre de connexions actives

### 2. Augmenter encore le pool (si nÃ©cessaire)

Si vous avez vraiment beaucoup de trafic simultanÃ© :

```python
pool_size=15,        # Au lieu de 10
max_overflow=30,     # Au lieu de 20
# Total = 45 connexions (toujours en dessous de 100 pour Supabase)
```

### 3. Identifier les requÃªtes longues

Les requÃªtes qui prennent du temps gardent les connexions occupÃ©es. VÃ©rifiez :
- Les endpoints qui font beaucoup de calculs
- Les requÃªtes SQL complexes
- Les boucles qui font plusieurs requÃªtes

### 4. Optimiser les requÃªtes

- Utiliser `.limit()` pour limiter les rÃ©sultats
- Utiliser des index sur les colonnes frÃ©quemment recherchÃ©es
- Ã‰viter les `N+1 queries` (utiliser `.joinedload()` ou `.select_related()`)

## ğŸ“ Monitoring

Pour surveiller l'utilisation du pool, vous pouvez ajouter ce logging :

```python
import logging
logger = logging.getLogger(__name__)

# Dans votre code, aprÃ¨s une requÃªte importante
logger.info(f"Pool stats: {engine.pool.size()} connections, {engine.pool.checkedout()} in use")
```

## âœ… RÃ©sultat attendu

AprÃ¨s cette correction :
- âœ… Plus de timeout sur les connexions
- âœ… Support jusqu'Ã  **30 requÃªtes simultanÃ©es**
- âœ… Connexions recyclÃ©es automatiquement (Ã©vite les connexions mortes)
- âœ… VÃ©rification automatique de la santÃ© des connexions

---

**Date de correction** : DÃ©cembre 2024  
**Fichier modifiÃ©** : `backend/app/db/session.py`
