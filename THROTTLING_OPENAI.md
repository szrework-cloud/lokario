# ğŸš¦ Throttling des requÃªtes OpenAI

## ğŸ“‹ ProblÃ¨me identifiÃ©

L'application rencontrait des erreurs `429 Too Many Requests` lors des appels Ã  l'API OpenAI, ce qui indiquait que le nombre de requÃªtes par seconde dÃ©passait les limites autorisÃ©es par OpenAI.

```
2025-12-25 18:28:16 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
```

## ğŸ” Causes identifiÃ©es

1. **Appels simultanÃ©s** : Plusieurs services OpenAI (`ai_classifier`, `ai_reply`, `chatbot`) peuvent faire des appels en mÃªme temps
2. **Pas de throttling** : Aucun systÃ¨me de limitation de taux cÃ´tÃ© application
3. **Rate limits OpenAI** : OpenAI limite le nombre de requÃªtes par minute/seconde selon le plan

## âœ… Solution implÃ©mentÃ©e

### Module de throttling centralisÃ© (`backend/app/core/openai_throttle.py`)

Un module centralisÃ© qui garantit un dÃ©lai minimum entre chaque requÃªte OpenAI :

```python
def throttle_openai_request():
    """
    Throttle les requÃªtes OpenAI pour Ã©viter de dÃ©passer les rate limits.
    Assure un dÃ©lai minimum entre les requÃªtes.
    """
    # Thread-safe avec verrouillage
    # DÃ©lai minimum: 0.35 secondes (â‰ˆ 3 requÃªtes/seconde max)
```

### CaractÃ©ristiques

- **Thread-safe** : Utilise un `threading.Lock()` pour garantir le dÃ©lai mÃªme avec des threads multiples
- **DÃ©lai minimum** : 0.35 secondes entre chaque requÃªte (â‰ˆ 3 requÃªtes/seconde maximum)
- **Global** : Une seule instance partagÃ©e entre tous les services OpenAI

### Services modifiÃ©s

1. **`ai_classifier_service.py`** : Classification automatique des messages
   - `classify_messages_batch()`
   - `classify_message_to_folder()`
   - `is_notification_email()`
   - `is_notification_email_batch()`
   - `is_real_client_email()`

2. **`ai_reply_service.py`** : GÃ©nÃ©ration de rÃ©ponses IA
   - `generate_reply()`

3. **`chatbot_service.py`** : Service de chatbot
   - `generate_response()`

### Utilisation

Chaque appel Ã  `self.client.chat.completions.create()` est prÃ©cÃ©dÃ© de `throttle_openai_request()` :

```python
# Throttle pour Ã©viter les rate limits
throttle_openai_request()

# Appel Ã  l'API OpenAI
response = self.client.chat.completions.create(
    model="gpt-4o-mini",
    messages=api_messages,
    ...
)
```

## ğŸ“Š Impact attendu

1. **RÃ©duction des erreurs 429** : Le throttling prÃ©ventif Ã©vite de dÃ©passer les limites
2. **StabilitÃ© accrue** : Les requÃªtes sont espacÃ©es pour Ã©viter les pics de trafic
3. **Pas d'impact sur les performances** : Le dÃ©lai de 0.35s est nÃ©gligeable par rapport au temps de rÃ©ponse OpenAI (gÃ©nÃ©ralement 1-3 secondes)

## ğŸ”§ Configuration

Le dÃ©lai minimum peut Ãªtre ajustÃ© dans `backend/app/core/openai_throttle.py` :

```python
_openai_min_delay_seconds = 0.35  # DÃ©lai minimum entre requÃªtes
```

**Recommandations** :
- **0.35s** : Pour plans OpenAI standard (â‰ˆ 3 req/s max)
- **0.5s** : Si vous avez encore des erreurs 429 (â‰ˆ 2 req/s max)
- **0.2s** : Si vous avez un plan avec limites plus Ã©levÃ©es (â‰ˆ 5 req/s max)

## ğŸ“ Notes importantes

- Le throttling est **global** : tous les services partagent la mÃªme limite
- Le systÃ¨me est **thread-safe** : fonctionne correctement avec des requÃªtes simultanÃ©es
- Le fallback existant reste actif : en cas d'erreur 429, le systÃ¨me fait un fallback gracieux (pas de classification IA, mais l'application continue de fonctionner)

## ğŸš€ DÃ©ploiement

Ces modifications ont Ã©tÃ© dÃ©ployÃ©es sur la branche `main` et seront automatiquement dÃ©ployÃ©es en production via Railway.

## ğŸ”„ Monitoring

Surveillez les logs pour vÃ©rifier que les erreurs 429 ont disparu :

```bash
# Chercher les erreurs 429
grep "429" logs/*.log

# Chercher les messages de throttling (niveau DEBUG)
grep "AI THROTTLE" logs/*.log
```

Si des erreurs 429 persistent, augmentez `_openai_min_delay_seconds` Ã  0.5 ou 0.6 secondes.

## ğŸ“š RÃ©fÃ©rences

- `backend/app/core/openai_throttle.py` : Module de throttling
- `backend/app/core/ai_classifier_service.py` : Service de classification
- `backend/app/core/ai_reply_service.py` : Service de gÃ©nÃ©ration de rÃ©ponses
- `backend/app/core/chatbot_service.py` : Service de chatbot

